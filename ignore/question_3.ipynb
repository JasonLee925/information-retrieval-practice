{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from q1_3 import get_stop_words\n",
    "from q1_1 import Parse_Docs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'suppos': 2, 'suzuki': 13, 'motor': 3, 'corp': 2, 'answer': 2, 'those': 1, 'adventuresom': 1, 'hipster': 1, 'pursu': 1, 'call': 1, 'extrem': 2, 'sport': 4, 'skyboard': 1, 'women': 1, 'box': 1, 'onli': 2, 'thing': 1, 'dismal': 1, 'sale': 6, 'record': 1, 'first': 1, 'eight': 1, 'month': 2, 'sold': 1, 'stubbi': 1, 'top': 1, 'hybrid': 1, 'between': 1, 'two': 4, 'seat': 2, 'car': 3, 'util': 3, 'vehicl': 7, 'compani': 4, 'offici': 2, 'predict': 1, 'sell': 2, 'introduc': 2, 'year': 6, 'ago': 1, 'further': 1, 'insult': 1, 'promot': 2, 'usual': 1, 'reserv': 1, 'day': 1, 'old': 1, 'doughnut': 1, 'buy': 2, 'one': 6, 'free': 2, 'bob': 2, 'sak': 2, 'oldsmobil': 1, 'farmington': 1, 'hill': 1, 'mich': 1, 'person': 1, 'cutlass': 1, 'suprem': 1, 'receiv': 1, 'leas': 1, 'long': 1, 'small': 1, 'player': 1, 'domest': 1, 'market': 2, 'reach': 1, 'peak': 1, 'unit': 1, 'batter': 1, 'news': 1, 'consum': 1, 'group': 1, 'report': 1, 'samuri': 2, 'minisport': 1, 'prone': 1, 'tip': 1, 'over': 1, 'deni': 1, 'charg': 2, 'never': 1, 'recov': 1, 'fall': 1, 'last': 1, 'new': 2, 'design': 1, 'help': 1, 'japanes': 1, 'automak': 2, 'forg': 1, 'imag': 1, 'mind': 1, 'american': 2, 'buyer': 3, 'associ': 1, 'rollov': 1, 'controversi': 1, 'later': 2, 'far': 1, 'below': 1, 'even': 1, 'modest': 1, 'target': 1, 'probabl': 1, 'disappoint': 1, 'product': 4, 'next': 1, 'steve': 1, 'kosowski': 2, 'analyst': 2, 'autopacif': 1, 'inc': 1, 'consult': 1, 'firm': 1, 'santa': 1, 'ana': 1, 'calif': 1, 'went': 1, 'wrong': 1, 'concept': 1, 'flaw': 1, 'door': 2, 'model': 2, 'virtual': 1, 'trunk': 1, 'space': 1, 'minim': 1, 'interior': 1, 'storag': 1, 'good': 1, 'activ': 1, 'lifestyl': 1, 'kind': 1, 'question': 1, 'nobodi': 1, 'ask': 1, 'posit': 1, 'four': 3, 'wheel': 2, 'drive': 2, 'anywher': 1, 'runabout': 1, 'criticis': 1, 'limit': 1, 'power': 1, 'excess': 1, 'road': 1, 'nois': 1, 'mediocr': 1, 'handl': 1, 'unfortun': 1, 'fact': 1, 'competit': 1, 'stiffer': 1, 'mini': 1, 'segment': 1, 'rav': 1, 'toyota': 1, 'proven': 1, 'hit': 1, 'price': 4, 'conscious': 1, 'look': 1, 'practic': 1, 'base': 1, 'honda': 1, 'ltd': 1, 'enter': 1, 'field': 1, 'stick': 1, 'behind': 1, 'howev': 1, 'argu': 1, 'take': 1, 'time': 1, 'creat': 1, 'suffici': 1, 'awar': 1, 'generat': 1, 'follow': 1, 'dealer': 2, 'aim': 1, 'ann': 1, 'bryan': 2, 'spokeswoman': 1, 'veri': 1, 'uniqu': 1, 'peopl': 1, 'love': 1, 'hate': 1, 'need': 2, 'chanc': 1, 'catch': 1, 'declin': 1, 'outlin': 1, 'advertis': 1, 'plan': 2, 'consid': 1, 'boost': 1, 'profil': 1, 'meantim': 1, 'ani': 1, 'special': 1, 'incent': 1, 'chang': 1, 'part': 1, 'brave': 1, 'tout': 1, 'nich': 2, 'find': 1, 'certain': 1, 'populac': 1, 'countri': 1, 'ken': 1, 'chancey': 2, 'manag': 1, 'kiril': 1, 'jacksonvill': 1, 'fla': 1, 'think': 1, 'bring': 1, 'down': 1, 'becaus': 1, 'troubl': 1, 'compet': 1, 'sidekick': 1, 'come': 1, 'version': 1, 'manual': 1, 'transmiss': 2, 'start': 1, 'deliveri': 1, 'automat': 1, 'air': 1, 'condit': 1, 'option': 1, 'push': 1, 'past': 1, 'mark': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "357.6666666666667"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 3-1\n",
    "stop_words = get_stop_words()\n",
    "docV3s = Parse_Docs(stop_words, \"RCV1v3/\")\n",
    "\n",
    "# for k, v in docV3s.items():\n",
    "#     if '80483' in k:\n",
    "#         print(v.terms)\n",
    "#         break\n",
    "\n",
    "\n",
    "def avg_length(coll: dict):\n",
    "     sum_of_length = sum(doc.doc_size for _,doc in coll.items())\n",
    "     return sum_of_length / len(coll)\n",
    " \n",
    " \n",
    "avg_length(docV3s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'741299': 2.612564748837137,\n",
       " '780723': 0.0,\n",
       " '741309': 0.0,\n",
       " '86961': 17.48588246669507,\n",
       " '780718': 0.0,\n",
       " '783803': 1.3032544561880095,\n",
       " '80483': 2.0611668818582434,\n",
       " '809481': 0.0,\n",
       " '809495': 0.0,\n",
       " '80484': 2.0611668818582434,\n",
       " '783802': 0.0,\n",
       " '807600': 0.0,\n",
       " '80884': 2.0611668818582434,\n",
       " '86042': 17.48588246669507,\n",
       " '807606': 0.0}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3-2\n",
    "import math\n",
    "from q1_2 import Parse_Q\n",
    "from q2_1 import df\n",
    "from q1_3 import get_stop_words\n",
    "\n",
    "\n",
    "def my_bm25(coll: dict, q, df):\n",
    "    k1 = 1.2\n",
    "    k2 = 100\n",
    "    b = 0.75\n",
    "    N = len(coll)\n",
    "\n",
    "    # compute avg doc length\n",
    "    avg_len = avg_length(coll)\n",
    "\n",
    "    # Tokenize query\n",
    "    query_terms = Parse_Q(q, stop_words)\n",
    "    \n",
    "\n",
    "    scores = {}\n",
    "\n",
    "    for _, doc in coll.items():\n",
    "        doc_len = doc.doc_size\n",
    "        doc_tf = doc.terms\n",
    "        score = 0\n",
    "\n",
    "        for term in query_terms:\n",
    "            if term not in df or df[term] == 0:\n",
    "                continue  # Skip terms not found in DF dictionary\n",
    "\n",
    "            f_i = doc_tf[term] if term in doc_tf else 0\n",
    "            n_i = df[term]\n",
    "            qf_i = query_terms[term]\n",
    "\n",
    "            idf = math.log((N - n_i + 0.5) / (n_i + 0.5) + 1)  # \n",
    "\n",
    "            K = k1 * ((1 - b) + b * (doc_len / avg_len))\n",
    "            tf_component = ((k1 + 1) * f_i) / (K + f_i) if f_i > 0 else 0\n",
    "            qf_component = ((k2 + 1) * qf_i) / (k2 + qf_i)          \n",
    "\n",
    "            score += idf * tf_component  *qf_component\n",
    "\n",
    "        scores[doc.newsID] = score\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "stop_words = get_stop_words()\n",
    "docV3s = Parse_Docs(stop_words, \"RCV1v3/\")\n",
    "dfs = df(docV3s)\n",
    "my_bm25(docV3s, \"US EPA ranks Geo Metro car most fuel-efficient 1997 car.\",  dfs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('86961', 17.48588246669507),\n",
       " ('86042', 17.48588246669507),\n",
       " ('741299', 2.612564748837137),\n",
       " ('80483', 2.0611668818582434),\n",
       " ('80484', 2.0611668818582434)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3-3\n",
    "\n",
    "bm25_result = my_bm25(docV3s, \"US EPA ranks Geo Metro car most fuel-efficient 1997 car.\",  dfs)\n",
    "sorted(bm25_result.items(), key=lambda x: x[1], reverse=True)[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
